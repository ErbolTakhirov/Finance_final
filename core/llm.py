import json
import hashlib
import re
from typing import List, Dict, Any, Optional, Set

import requests
from django.conf import settings
from django.db.models import Q

from core.models import ChatMessage, ChatSession
from core.utils.anonymizer import anonymize_text, anonymize_csv_data
from core.utils.analytics import (
    get_user_financial_memory,
    build_system_prompt,
    parse_actionable_items,
    detect_anomalies_automatically,
)


# ============================================================================
# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø API LLM
# ============================================================================
# –í—Å—Ç–∞–≤—å—Ç–µ –≤–∞—à API –∫–ª—é—á –≤ settings.py –∏–ª–∏ .env —Ñ–∞–π–ª:
# LLM_API_KEY=your_api_key_here
# LLM_API_URL=https://openrouter.ai/api/v1/chat/completions
# LLM_MODEL=openai/gpt-4o-mini
# ============================================================================

def _headers() -> Dict[str, str]:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM API.
    OpenRouter —Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏.
    """
    headers = {
        'Content-Type': 'application/json',
    }
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ API –∫–ª—é—á –Ω–∞—Å—Ç—Ä–æ–µ–Ω –∏ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ø—Ä–∏–º–µ—Ä–æ–º
    if not settings.LLM_API_KEY or settings.LLM_API_KEY in ['your_api_key_here', 'sk-or-v1-your-key-here']:
        # –î–µ–º–æ-—Ä–µ–∂–∏–º: –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –±–µ–∑ API –∫–ª—é—á–∞
        return headers
    
    headers['Authorization'] = f"Bearer {settings.LLM_API_KEY}"
    
    # OpenRouter —Ç—Ä–µ–±—É–µ—Ç —ç—Ç–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –Ω–æ —Ä–µ–∫–æ–º–µ–Ω–¥—É—é—Ç—Å—è)
    # Referer: URL –≤–∞—à–µ–≥–æ —Å–∞–π—Ç–∞ (–¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è API)
    # X-Title: –ù–∞–∑–≤–∞–Ω–∏–µ –≤–∞—à–µ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è (–¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–µ OpenRouter)
    referer = getattr(settings, 'LLM_HTTP_REFERER', 'http://localhost:8000')
    app_title = getattr(settings, 'LLM_APP_TITLE', 'SB Finance AI')
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã
    if referer:
        headers['Referer'] = referer
    if app_title:
        headers['X-Title'] = app_title
    
    return headers


def _compute_content_hash(content: str) -> str:
    """–í—ã—á–∏—Å–ª—è–µ—Ç SHA256 —Ö–µ—à —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è"""
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º: —É–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã, –ø—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    normalized = re.sub(r'\s+', ' ', content.strip().lower())
    return hashlib.sha256(normalized.encode('utf-8')).hexdigest()


def _extract_advice_snippets(content: str) -> List[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–æ–≤–µ—Ç—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è"""
    snippets = []
    # –ò—â–µ–º —Å–ø–∏—Å–∫–∏, –ø—É–Ω–∫—Ç—ã, –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
    lines = content.split('\n')
    current_snippet = []
    for line in lines:
        line = line.strip()
        if not line:
            if current_snippet:
                snippets.append(' '.join(current_snippet))
                current_snippet = []
            continue
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å –º–∞—Ä–∫–µ—Ä–∞ —Å–ø–∏—Å–∫–∞
        if re.match(r'^[-*‚Ä¢\d+\.]', line):
            if current_snippet:
                snippets.append(' '.join(current_snippet))
            current_snippet = [line]
        else:
            current_snippet.append(line)
    if current_snippet:
        snippets.append(' '.join(current_snippet))
    return snippets


def _check_for_duplicates(new_content: str, session: ChatSession, similarity_threshold: float = 0.8) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –µ—Å—Ç—å –ª–∏ –ø–æ—Ö–æ–∂–∏–µ —Å–æ–≤–µ—Ç—ã –≤ –∏—Å—Ç–æ—Ä–∏–∏ —Å–µ—Å—Å–∏–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True, –µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã –¥—É–±–ª–∏–∫–∞—Ç—ã.
    similarity_threshold: –ø–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ (0-1), –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.8
    """
    new_hash = _compute_content_hash(new_content)
    new_snippets = _extract_advice_snippets(new_content)
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –æ—Ç–≤–µ—Ç—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –≤ —ç—Ç–æ–π —Å–µ—Å—Å–∏–∏
    previous_messages = ChatMessage.objects.filter(
        session=session,
        role='assistant'
    ).exclude(content_hash=new_hash)
    
    for prev_msg in previous_messages:
        prev_hash = prev_msg.content_hash
        # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ —Ö–µ—à—É
        if new_hash == prev_hash:
            return True
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞–º
        prev_snippets = _extract_advice_snippets(prev_msg.content)
        for new_snip in new_snippets:
            new_snip_hash = _compute_content_hash(new_snip)
            for prev_snip in prev_snippets:
                prev_snip_hash = _compute_content_hash(prev_snip)
                # –ï—Å–ª–∏ —Ö–µ—à–∏ —Å–æ–≤–ø–∞–¥–∞—é—Ç –∏–ª–∏ –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–∏ –ø–æ –¥–ª–∏–Ω–µ –∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é
                if new_snip_hash == prev_snip_hash:
                    return True
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ –æ–¥–∏–Ω —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –¥—Ä—É–≥–æ–π
                if len(new_snip) > 20 and len(prev_snip) > 20:
                    new_lower = new_snip.lower()
                    prev_lower = prev_snip.lower()
                    if new_lower in prev_lower or prev_lower in new_lower:
                        return True
    
    return False


def get_ai_advice_from_data(data_blob: str, extra_instruction: str = "", anonymize: bool = True, user=None) -> str:
    """
    Sends a single-shot prompt with user data embedded into the system message.
    data_blob: CSV or compact JSON string with user's transactions/metrics.
    extra_instruction: optional user question or context.
    anonymize: –µ—Å–ª–∏ True, –∞–Ω–æ–Ω–∏–º–∏–∑–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –≤ –æ–±–ª–∞–∫–æ.
    user: User –æ–±—ä–µ–∫—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–π –ø–∞–º—è—Ç–∏ (—Ç–∞–±–ª–∏—Ü, summary)
    """
    # –î–µ–º–æ-—Ä–µ–∂–∏–º –±–µ–∑ API –∫–ª—é—á–∞
    if not settings.LLM_API_KEY or settings.LLM_API_KEY in ['your_api_key_here', 'sk-or-v1-your-key-here']:
        demo_responses = [
            "ü§ñ **–î–ï–ú–û-–†–ï–ñ–ò–ú**: –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ SB Finance AI!\n\n–î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∞–ª—å–Ω—ã—Ö —Å–æ–≤–µ—Ç–æ–≤ –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ API –∫–ª—é—á –≤ .env —Ñ–∞–π–ª–µ.\n\n**–ü—Ä–∏–º–µ—Ä —Å–æ–≤–µ—Ç–∞**: –í–∞–º —Å–ª–µ–¥—É–µ—Ç —Ä–∞–∑–±–∏—Ç—å —Ä–∞—Å—Ö–æ–¥—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª—è –±—é–¥–∂–µ—Ç–∞.",
            "ü§ñ **–î–ï–ú–û-–†–ï–ñ–ò–ú**: AI –ø–æ–º–æ—â–Ω–∏–∫ –≥–æ—Ç–æ–≤ –ø–æ–º–æ—á—å —Å –∞–Ω–∞–ª–∏–∑–æ–º —Ñ–∏–Ω–∞–Ω—Å–æ–≤!\n\n**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è**: –†–µ–≥—É–ª—è—Ä–Ω–æ –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –¥–æ—Ö–æ–¥–æ–≤ –∏ —Ä–∞—Å—Ö–æ–¥–æ–≤.",
            "ü§ñ **–î–ï–ú–û-–†–ï–ñ–ò–ú**: –ü–æ–ª—É—á–∏—Ç–µ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Å–æ–≤–µ—Ç—ã!\n\n**–°–æ–≤–µ—Ç**: –°–æ–∑–¥–∞–π—Ç–µ —Ä–µ–∑–µ—Ä–≤–Ω—ã–π —Ñ–æ–Ω–¥ –Ω–∞ —Å–ª—É—á–∞–π –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω—ã—Ö —Ä–∞—Å—Ö–æ–¥–æ–≤."
        ]
        import random
        return random.choice(demo_responses)
    # –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω user, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∏–Ω–∞–Ω—Å–æ–≤—É—é –ø–∞–º—è—Ç—å —Å —Ç–∞–±–ª–∏—Ü–∞–º–∏
    if user:
        try:
            memory = get_user_financial_memory(user, force_refresh=False)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –ø–æ–ª–µ–π –≤ –ø–∞–º—è—Ç–∏
            if memory and isinstance(memory, dict) and memory.get('table_markdown'):
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç —Å —Ç–∞–±–ª–∏—Ü–∞–º–∏
                system_content = build_system_prompt(memory, extra_context=data_blob or "")
            else:
                # Fallback –Ω–∞ —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç, –µ—Å–ª–∏ –ø–∞–º—è—Ç—å –ø—É—Å—Ç–∞—è –∏–ª–∏ –Ω–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
                if anonymize:
                    anonymized_data = anonymize_csv_data(data_blob)
                    system_content = settings.LLM_PROMPT_TEMPLATE.format(user_data=anonymized_data)
                else:
                    system_content = settings.LLM_PROMPT_TEMPLATE.format(user_data=data_blob)
        except Exception as e:
            # Fallback –Ω–∞ —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ
            import traceback
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–π –ø–∞–º—è—Ç–∏ –¥–ª—è AI: {e}")
            print(traceback.format_exc())
            if anonymize:
                anonymized_data = anonymize_csv_data(data_blob)
                system_content = settings.LLM_PROMPT_TEMPLATE.format(user_data=anonymized_data)
            else:
                system_content = settings.LLM_PROMPT_TEMPLATE.format(user_data=data_blob)
    else:
        # –°—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç –±–µ–∑ –ø–∞–º—è—Ç–∏
        if anonymize:
            anonymized_data = anonymize_csv_data(data_blob)
            system_content = settings.LLM_PROMPT_TEMPLATE.format(user_data=anonymized_data)
        else:
            system_content = settings.LLM_PROMPT_TEMPLATE.format(user_data=data_blob)
    
    messages = [
        {"role": "system", "content": system_content},
    ]
    if extra_instruction:
        messages.append({"role": "user", "content": extra_instruction})

    # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª—å –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∑–∞–ø—Ä–æ—Å–∞
    model = getattr(settings, 'LLM_MODEL', 'deepseek-chat-v3.1:free')
    
    payload = {
        "model": model,  # –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º –º–æ–¥–µ–ª—å –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö –∑–∞–ø—Ä–æ—Å–∞
        "messages": messages,
        "max_tokens": getattr(settings, 'LLM_MAX_TOKENS', 4000),  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ç–æ–∫–µ–Ω—ã –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏
    }
    try:
        resp = requests.post(settings.LLM_API_URL, headers=_headers(), json=payload, timeout=60)
        
        if resp.status_code != 200:
            error_detail = f"HTTP {resp.status_code}"
            try:
                error_data = resp.json()
                if 'error' in error_data:
                    error_msg = error_data['error'].get('message', str(error_data['error']))
                    error_detail = error_msg
                    
                    # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ API –∫–ª—é—á–∞
                    if 'user not found' in error_msg.lower() or error_data['error'].get('code') == 401:
                        error_detail = f"–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π API –∫–ª—é—á: '{settings.LLM_API_KEY}'.\n\n–û—à–∏–±–∫–∞: {error_msg}\n\n–ü–æ–ª—É—á–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∫–ª—é—á –Ω–∞ https://openrouter.ai/keys –∏ –¥–æ–±–∞–≤—å—Ç–µ –µ–≥–æ –≤ .env —Ñ–∞–π–ª –∫–∞–∫ LLM_API_KEY."
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ª–∏–º–∏—Ç—ã free tier
                    elif 'limit' in error_msg.lower() or 'quota' in error_msg.lower() or 'free' in error_msg.lower():
                        error_detail = f"‚ö†Ô∏è –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –±–µ—Å–ø–ª–∞—Ç–Ω–æ–≥–æ —Ç–∞—Ä–∏—Ñ–∞. {error_msg}\n\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø–ª–∞—Ç–Ω—É—é –º–æ–¥–µ–ª—å –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö."
            except:
                error_detail = resp.text[:200] if resp.text else f"HTTP {resp.status_code}"
            return f"[AI –æ—à–∏–±–∫–∞] {error_detail}"
        
        data = resp.json()
        if 'choices' not in data or not data['choices']:
            return "[AI –æ—à–∏–±–∫–∞] –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç API."
        return data['choices'][0]['message']['content']
    except requests.exceptions.RequestException as ex:
        return f"[AI –æ—à–∏–±–∫–∞] –û—à–∏–±–∫–∞ —Å–µ—Ç–∏: {ex}"
    except Exception as ex:
        return f"[AI –æ—à–∏–±–∫–∞] –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏: {ex}"


def chat_with_context(
    messages: List[Dict[str, str]], 
    user_data: str = "",
    session: Optional[ChatSession] = None,
    check_duplicates: bool = True,
    anonymize: bool = True,
    use_local: bool = False,
    user=None
) -> str:
    """
    Chat-style call —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∏—Å—Ç–æ—Ä–∏–∏ –∏ –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è.
    
    Args:
        messages: list of {role: 'user'|'assistant'|'system', content: str}
        user_data: CSV/JSON compact data to ground the answers (–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç)
        session: ChatSession –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è
        check_duplicates: –µ—Å–ª–∏ True, –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è —Å–æ–≤–µ—Ç–æ–≤
        anonymize: –µ—Å–ª–∏ True, –∞–Ω–æ–Ω–∏–º–∏–∑–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –≤ –æ–±–ª–∞–∫–æ
        use_local: –µ—Å–ª–∏ True, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å (Ollama)
        user: User –æ–±—ä–µ–∫—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–π –ø–∞–º—è—Ç–∏
    
    Returns:
        –û—Ç–≤–µ—Ç –æ—Ç LLM
    """
    # –î–µ–º–æ-—Ä–µ–∂–∏–º –±–µ–∑ API –∫–ª—é—á–∞
    if not settings.LLM_API_KEY or settings.LLM_API_KEY in ['your_api_key_here', 'sk-or-v1-your-key-here']:
        demo_responses = [
            "ü§ñ **–î–ï–ú–û-–†–ï–ñ–ò–ú**: –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ SB Finance AI!\n\n–î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∞–ª—å–Ω—ã—Ö —Å–æ–≤–µ—Ç–æ–≤ –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ API –∫–ª—é—á –≤ .env —Ñ–∞–π–ª–µ.\n\n**–ü—Ä–∏–º–µ—Ä –æ—Ç–≤–µ—Ç–∞**: –°—É–¥—è –ø–æ –≤–∞—à–µ–º—É —Å–æ–æ–±—â–µ–Ω–∏—é, –≤–∞—Å –∏–Ω—Ç–µ—Ä–µ—Å—É—é—Ç —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã. –†–µ–∫–æ–º–µ–Ω–¥—É—é –Ω–∞—á–∞—Ç—å —Å –∞–Ω–∞–ª–∏–∑–∞ –¥–æ—Ö–æ–¥–æ–≤ –∏ —Ä–∞—Å—Ö–æ–¥–æ–≤.",
            "ü§ñ **–î–ï–ú–û-–†–ï–ñ–ò–ú**: AI –ø–æ–º–æ—â–Ω–∏–∫ –≥–æ—Ç–æ–≤ –ø–æ–º–æ—á—å!\n\n**–û—Ç–≤–µ—Ç –Ω–∞ –≤–∞—à –≤–æ–ø—Ä–æ—Å**: –í –¥–µ–º–æ-—Ä–µ–∂–∏–º–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã. –í —Ä–µ–∞–ª—å–Ω–æ–º —Ä–µ–∂–∏–º–µ AI –¥–∞—Å—Ç –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–æ–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∞—à–∏—Ö —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö.",
            "ü§ñ **–î–ï–ú–û-–†–ï–ñ–ò–ú**: –°–ø–∞—Å–∏–±–æ –∑–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ!\n\n**–°–æ–≤–µ—Ç**: –î–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã —Ä–µ–∫–æ–º–µ–Ω–¥—É—é –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤–∞—à–∏ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ —Ä–∞–∑–¥–µ–ª \"–ò–º–ø–æ—Ä—Ç\"."
        ]
        import random
        return random.choice(demo_responses)
    
    # –õ–æ–∫–∞–ª—å–Ω—ã–π —Ä–µ–∂–∏–º (Ollama)
    if use_local:
        return _call_local_llm(messages, user_data, user=user)
    
    # –ü–æ–ª—É—á–∞–µ–º —Ñ–∏–Ω–∞–Ω—Å–æ–≤—É—é –ø–∞–º—è—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (—Ç–∞–±–ª–∏—Ü—ã, summary, alerts)
    memory = None
    if user:
        try:
            memory = get_user_financial_memory(user, force_refresh=False)
        except Exception:
            pass
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å —Ç–∞–±–ª–∏—Ü–∞–º–∏ –∏ summary –∏–∑ –ø–∞–º—è—Ç–∏
    if memory:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç –ø—Ä–æ–º–ø—Ç–∞ —Å —Ç–∞–±–ª–∏—Ü–∞–º–∏
        sys_prompt = build_system_prompt(memory, extra_context=user_data or "")
    else:
        # Fallback –Ω–∞ —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç, –µ—Å–ª–∏ –ø–∞–º—è—Ç–∏ –Ω–µ—Ç
        if anonymize and user_data:
            anonymized_data = anonymize_csv_data(user_data)
        else:
            anonymized_data = user_data
        sys_prompt = settings.LLM_PROMPT_TEMPLATE.format(user_data=anonymized_data or "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –æ –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º–æ—Å—Ç–∏ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π
    if check_duplicates and session:
        sys_prompt += "\n\n–í–ê–ñ–ù–û: –ù–µ –ø–æ–≤—Ç–æ—Ä—è–π —Ä–∞–Ω–µ–µ –¥–∞–Ω–Ω—ã–µ —Å–æ–≤–µ—Ç—ã –≤ —ç—Ç–æ–π —Å–µ—Å—Å–∏–∏. –í—Å–µ–≥–¥–∞ –¥–∞–≤–∞–π –Ω–æ–≤—ã–µ, —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏."
    
    # –ê–Ω–æ–Ω–∏–º–∏–∑–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ–±–ª–∞–∫–æ –∏ –ø–∞–º—è—Ç—å –Ω–µ –∞–Ω–æ–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞)
    if anonymize and not memory:
        anonymized_messages = []
        for msg in messages:
            if msg['role'] == 'user':
                anonymized_messages.append({
                    'role': msg['role'],
                    'content': anonymize_text(msg['content'])
                })
            else:
                anonymized_messages.append(msg)
        messages = anonymized_messages
    elif anonymize and memory:
        # –ê–Ω–æ–Ω–∏–º–∏–∑–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è, –Ω–æ –Ω–µ —Ç–∞–±–ª–∏—Ü—ã
        anonymized_messages = []
        for msg in messages:
            if msg['role'] == 'user':
                anonymized_messages.append({
                    'role': msg['role'],
                    'content': anonymize_text(msg['content'])
                })
            else:
                anonymized_messages.append(msg)
        messages = anonymized_messages
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ (—Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –º–æ–≥—É—Ç –≤—ã–∑—ã–≤–∞—Ç—å –æ—à–∏–±–∫–∏)
    max_system_length = 8000  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ª–∏–º–∏—Ç –¥–ª—è —Ç–∞–±–ª–∏—Ü
    if len(sys_prompt) > max_system_length:
        # –û–±—Ä–µ–∑–∞–µ–º —Ç–æ–ª—å–∫–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç, —Å–æ—Ö—Ä–∞–Ω—è—è —Ç–∞–±–ª–∏—Ü—ã
        if "### –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç" in sys_prompt:
            parts = sys_prompt.split("### –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç")
            sys_prompt = parts[0] + "\n\n### –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç\n[–î–∞–Ω–Ω—ã–µ –æ–±—Ä–µ–∑–∞–Ω—ã –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏]"
        else:
            sys_prompt = sys_prompt[:max_system_length] + "\n\n[–î–∞–Ω–Ω—ã–µ –æ–±—Ä–µ–∑–∞–Ω—ã –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏]"
    
    full_messages = [{"role": "system", "content": sys_prompt}] + messages
    
    # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª—å –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∑–∞–ø—Ä–æ—Å–∞
    model = getattr(settings, 'LLM_MODEL', 'deepseek-chat-v3.1:free')
    
    payload = {
        "model": model,  # –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º –º–æ–¥–µ–ª—å –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö –∑–∞–ø—Ä–æ—Å–∞
        "messages": full_messages,
        "max_tokens": getattr(settings, 'LLM_MAX_TOKENS', 4000),  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ç–æ–∫–µ–Ω—ã –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏
    }
    
    try:
        resp = requests.post(settings.LLM_API_URL, headers=_headers(), json=payload, timeout=60)
        
        # –£–ª—É—á—à–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
        if resp.status_code != 200:
            error_detail = f"HTTP {resp.status_code}"
            try:
                error_data = resp.json()
                if 'error' in error_data:
                    error_msg = error_data['error'].get('message', str(error_data['error']))
                    error_detail = error_msg
                    
                    # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ API –∫–ª—é—á–∞
                    if 'user not found' in error_msg.lower() or error_data['error'].get('code') == 401:
                        error_detail = f"–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π API –∫–ª—é—á: '{settings.LLM_API_KEY}'.\n\n–û—à–∏–±–∫–∞: {error_msg}\n\n–ü–æ–ª—É—á–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∫–ª—é—á –Ω–∞ https://openrouter.ai/keys –∏ –¥–æ–±–∞–≤—å—Ç–µ –µ–≥–æ –≤ .env —Ñ–∞–π–ª –∫–∞–∫ LLM_API_KEY."
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ª–∏–º–∏—Ç—ã free tier
                    elif 'limit' in error_msg.lower() or 'quota' in error_msg.lower() or 'free' in error_msg.lower():
                        error_detail = f"‚ö†Ô∏è –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –±–µ—Å–ø–ª–∞—Ç–Ω–æ–≥–æ —Ç–∞—Ä–∏—Ñ–∞. {error_msg}\n\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø–ª–∞—Ç–Ω—É—é –º–æ–¥–µ–ª—å –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö."
                elif 'message' in error_data:
                    error_detail = error_data['message']
            except:
                error_detail = resp.text[:200] if resp.text else f"HTTP {resp.status_code}"
            
            return f"[AI –æ—à–∏–±–∫–∞] {error_detail}\n\n–ü—Ä–æ–≤–µ—Ä—å—Ç–µ:\n- –ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å API –∫–ª—é—á–∞ –≤ .env —Ñ–∞–π–ª–µ\n- –ù–∞–ª–∏—á–∏–µ –±–∞–ª–∞–Ω—Å–∞ –Ω–∞ OpenRouter (–¥–ª—è –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –º–æ–∂–µ—Ç –±—ã—Ç—å –ª–∏–º–∏—Ç)\n- –§–æ—Ä–º–∞—Ç –∑–∞–ø—Ä–æ—Å–∞"
        
        data = resp.json()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –æ—Ç–≤–µ—Ç–∞
        if 'choices' not in data or not data['choices']:
            return "[AI –æ—à–∏–±–∫–∞] –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç API. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏."
        
        reply = data['choices'][0]['message']['content']
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è, –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞
        if check_duplicates and session:
            if _check_for_duplicates(reply, session):
                # –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è, –¥–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é
                sys_prompt += "\n\n–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è –≤ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –æ—Ç–≤–µ—Ç–∞—Ö. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –¥–∞–π —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –Ω–æ–≤—ã–π, —É–Ω–∏–∫–∞–ª—å–Ω—ã–π —Å–æ–≤–µ—Ç, –∫–æ—Ç–æ—Ä—ã–π –µ—â–µ –Ω–µ –±—ã–ª –¥–∞–Ω –≤ —ç—Ç–æ–π —Å–µ—Å—Å–∏–∏."
                full_messages = [{"role": "system", "content": sys_prompt}] + messages
                payload['messages'] = full_messages
                # –ü–æ–≤—Ç–æ—Ä–Ω—ã–π –∑–∞–ø—Ä–æ—Å
                resp = requests.post(settings.LLM_API_URL, headers=_headers(), json=payload, timeout=60)
                if resp.status_code != 200:
                    # –ï—Å–ª–∏ –ø–æ–≤—Ç–æ—Ä–Ω—ã–π –∑–∞–ø—Ä–æ—Å —Ç–æ–∂–µ –Ω–µ —É–¥–∞–ª—Å—è, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç
                    return reply
                data = resp.json()
                if 'choices' in data and data['choices']:
                    reply = data['choices'][0]['message']['content']
        
        return reply
    except requests.exceptions.RequestException as ex:
        return f"[AI –æ—à–∏–±–∫–∞] –û—à–∏–±–∫–∞ —Å–µ—Ç–∏: {ex}\n\n–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É –∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å API."
    except KeyError as ex:
        return f"[AI –æ—à–∏–±–∫–∞] –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–ª–µ {ex}\n\n–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏ –∏ API."
    except Exception as ex:
        return f"[AI –æ—à–∏–±–∫–∞] –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {ex}\n\n–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ —Å–µ—Ä–≤–µ—Ä–∞ –¥–ª—è –¥–µ—Ç–∞–ª–µ–π."


def _call_local_llm(messages: List[Dict[str, str]], user_data: str = "", user=None) -> str:
    """
    –í—ã–∑—ã–≤–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω—É—é LLM —á–µ—Ä–µ–∑ Ollama API.
    –í–ê–ñ–ù–û: –î–∞–Ω–Ω—ã–µ –ù–ï –æ—Ç–ø—Ä–∞–≤–ª—è—é—Ç—Å—è –≤ –æ–±–ª–∞–∫–æ, –≤—Å—ë –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω–æ.
    
    Args:
        messages: –ò—Å—Ç–æ—Ä–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π
        user_data: –î–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user: User –æ–±—ä–µ–∫—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–π –ø–∞–º—è—Ç–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    
    Returns:
        –û—Ç–≤–µ—Ç –æ—Ç –ª–æ–∫–∞–ª—å–Ω–æ–π LLM
    """
    # URL –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ Ollama (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é localhost:11434)
    ollama_url = getattr(settings, 'OLLAMA_API_URL', 'http://localhost:11434/api/chat')
    ollama_model = getattr(settings, 'OLLAMA_MODEL', 'llama2')
    
    # –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω user, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∏–Ω–∞–Ω—Å–æ–≤—É—é –ø–∞–º—è—Ç—å
    if user:
        try:
            memory = get_user_financial_memory(user, force_refresh=False)
            if memory:
                sys_prompt = build_system_prompt(memory, extra_context=user_data or "")
            else:
                sys_prompt = settings.LLM_PROMPT_TEMPLATE.format(user_data=user_data or "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
        except Exception:
            sys_prompt = settings.LLM_PROMPT_TEMPLATE.format(user_data=user_data or "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
    else:
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        sys_prompt = settings.LLM_PROMPT_TEMPLATE.format(user_data=user_data or "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    full_messages = [{"role": "system", "content": sys_prompt}] + messages
    
    payload = {
        "model": ollama_model,
        "messages": full_messages,
        "stream": False
    }
    
    try:
        resp = requests.post(ollama_url, json=payload, timeout=120)
        
        if resp.status_code != 200:
            return f"[–õ–æ–∫–∞–ª—å–Ω–∞—è LLM –æ—à–∏–±–∫–∞] HTTP {resp.status_code}. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ Ollama –∑–∞–ø—É—â–µ–Ω."
        
        data = resp.json()
        if 'message' in data and 'content' in data['message']:
            return data['message']['content']
        elif 'response' in data:
            return data['response']
        else:
            return "[–õ–æ–∫–∞–ª—å–Ω–∞—è LLM –æ—à–∏–±–∫–∞] –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞."
    except requests.exceptions.ConnectionError:
        return "[–õ–æ–∫–∞–ª—å–Ω–∞—è LLM –æ—à–∏–±–∫–∞] –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Ollama. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ Ollama –∑–∞–ø—É—â–µ–Ω –Ω–∞ localhost:11434"
    except Exception as ex:
        return f"[–õ–æ–∫–∞–ª—å–Ω–∞—è LLM –æ—à–∏–±–∫–∞] {ex}"


